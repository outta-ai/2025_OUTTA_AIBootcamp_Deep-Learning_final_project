{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. ì‹¤í–‰ ì „ í•„ìˆ˜ ì•ˆë‚´\n",
        "\n",
        "* ë³¸ ì½”ë“œëŠ” GPU í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤!\n",
        "\n",
        "     \n",
        "     Colab ë©”ë‰´: [ëŸ°íƒ€ì„] â†’ [ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½] â†’ 'GPU' ì„ íƒ\n",
        "     \n",
        "      â†’ ì´ë¯¸ì§€ ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ, ì¶”ë¡  ì†ë„ê°€ í¬ê²Œ ê°œì„ ë©ë‹ˆë‹¤.\n",
        "\n",
        "### ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:\n",
        "- transformers: ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ë¯¸ì„¸ì¡°ì • (ğŸ¤— Hugging Face)\n",
        "- timm: Vision Transformer ê³„ì—´ ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "- scikit-learn: ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ê³„ì‚° (ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ë“±)\n",
        "- tqdm: í•™ìŠµ ë£¨í”„ ì§„í–‰ë¥  ì‹œê°í™”\n",
        "- PIL (Pillow): ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "GFWGA-uES2Ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. í™˜ê²½ ì„¤ì • ë° ê¸°ë³¸ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "JFlfCgLXwFOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PscHxnTwASM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c75431-3ba5-4af7-ffcf-d286bdf09afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "# Colab í™˜ê²½ì—ì„œëŠ” ìµœì´ˆ ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ ì„¤ì¹˜í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "!pip install transformers timm scikit-learn\n",
        "\n",
        "# Google Driveë¥¼ ë§ˆìš´íŠ¸í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "# ì½”ë“œ ì‹¤í–‰ ì‹œ ë‚˜íƒ€ë‚˜ëŠ” ì¸ì¦ ì ˆì°¨ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "G0J9GrLJRTQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ê²½ë¡œ ë° ë°ì´í„° ë¡œë”©\n",
        "* ë³¸ ì˜ˆì œì—ì„œëŠ” ë°ì´í„°ê°€ ì••ì¶•(zip) í˜•íƒœë¡œ Driveì— ì €ì¥ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
        "* ë³¸ì¸ì˜ Driveì— ì €ì¥ëœ zip íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ ì•„ë˜ ê²½ë¡œë“¤ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
        "* ì›¹í¬ë¡¤ë§ì„ í†µí•œ Inference ë˜í•œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "8Z-UONO-wULE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XX Modelë¡œ ìƒì„±í•œ fake ì´ë¯¸ì§€ (Nì¥ - í•™ìŠµìš©)\n",
        "xx_fake_path = \"/content/drive/MyDrive/Colab Notebooks/Deepfake_Detection/XX_fake_N.zip\"\n",
        "\n",
        "# í‰ê°€ìš© real ì´ë¯¸ì§€ (ì˜ˆ: XX ì¸ë¬¼ ì´ë¯¸ì§€)\n",
        "xx_real_path = \"/content/drive/MyDrive/Colab Notebooks/Deepfake_Detection/XX_real.zip\"\n",
        "\n",
        "# í‰ê°€ìš© fake ì´ë¯¸ì§€ (ì˜ˆ: XXìœ¼ë¡œ ìƒì„±í•œ 50ì¥)\n",
        "xx_fake_path2 = \"/content/drive/MyDrive/Colab Notebooks/Deepfake_Detection/XX_fake.zip\""
      ],
      "metadata": {
        "id": "d35MMs06wTPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ë°ì´í„° ë¡œë”© ë° í•¨ìˆ˜ ì •ì˜"
      ],
      "metadata": {
        "id": "eppEUpcFwbSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜ (í•™ìŠµìš©)\n",
        "def load_fake_images(zip_path):\n",
        "    \"\"\"\n",
        "    zip íŒŒì¼ ë‚´ ì´ë¯¸ì§€ë“¤ì„ ë¶ˆëŸ¬ì™€ (ì´ë¯¸ì§€ì´ë¦„, ì´ë¯¸ì§€ë°”ì´íŠ¸, ë¼ë²¨) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "    ë¼ë²¨ 1: FAKE\n",
        "    \"\"\"\n",
        "    fake_data = []\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        for name in zip_ref.namelist():\n",
        "            if name.endswith(('.jpg', '.png')):\n",
        "                fake_data.append((name, zip_ref.read(name), 1))\n",
        "    return fake_data\n",
        "\n",
        "# Custom Dataset í´ë˜ìŠ¤ ì •ì˜\n",
        "class FakeDataset(Dataset):\n",
        "    def __init__(self, data, processor):\n",
        "        self.data = data\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name, img_bytes, label = self.data[idx]\n",
        "        image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
        "        inputs[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
        "        return inputs\n",
        "\n",
        "# Real ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜ (í‰ê°€ìš©)\n",
        "def load_real_images(zip_path, limit=50):\n",
        "    \"\"\"\n",
        "    zip ë‚´ ìµœëŒ€ 50ì¥ì˜ real ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    real_images = []\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        for name in zip_ref.namelist():\n",
        "            if name.endswith(('.jpg', '.png')):\n",
        "                real_images.append((name, zip_ref.read(name)))\n",
        "                if len(real_images) >= limit:\n",
        "                    break\n",
        "    return real_images\n",
        "\n",
        "# Real ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "xx_real = load_real_images(xx_real_path)"
      ],
      "metadata": {
        "id": "yDTiC_rzwdOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ í‰ê°€ (Inference)\n",
        "í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "â†’ fakeì™€ real ì´ë¯¸ì§€ë¥¼ ë„£ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "\n",
        "â†’ Softmax í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ best thresholdë¥¼ ìë™ íƒìƒ‰í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "sxDLdDK33dmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"FAKE ê¸°ì¤€\"ì´ë€?\n",
        "\n",
        "â†’ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹œ **FAKE í´ë˜ìŠ¤(=1ë¡œ ë ˆì´ë¸”ë§ëœ í´ë˜ìŠ¤)**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•˜ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "â†’ ì˜ˆë¥¼ ë“¤ì–´, precisionì€ \"FAKEë¼ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì§„ì§œ FAKE ë¹„ìœ¨\",\n",
        "\n",
        "    recallì€ \"ì‹¤ì œ FAKE ì¤‘ì—ì„œ ë§ê²Œ ì˜ˆì¸¡í•œ ë¹„ìœ¨\"ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "### Threshold íƒìƒ‰ ì´ìœ ?\n",
        "\n",
        "â†’ ëª¨ë¸ ì¶œë ¥ì€ softmax í™•ë¥ ì´ë¯€ë¡œ, ì •í™•í•œ ì˜ˆì¸¡ì„ ìœ„í•´ í™•ë¥ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ\n",
        "   \n",
        "    ì˜ˆì¸¡ ê¸°ì¤€ì„ ì„ (0.05 ~ 0.99 ì‚¬ì´ì—ì„œ) ìµœì í™”í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "x63upYC-UYZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¡œë”©\n",
        "processor = AutoImageProcessor.from_pretrained(\"Pretrained_Model\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"Pretrained_Model\").to(\"cuda\")\n",
        "\n",
        "print(model.config.id2label)"
      ],
      "metadata": {
        "id": "_YpwJ53s1FSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd0b153-4195-410e-cdea-2f189bcfeea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Real', 1: 'Fake'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realê³¼ Fake Labelì— ë§ì¶”ì–´ í‰ê°€ í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”!"
      ],
      "metadata": {
        "id": "PQtRoLxVvVnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
        "def evaluate_real_vs_fake(real_images, fake_zip_path, fake_limit=50):\n",
        "    \"\"\"\n",
        "    ëª¨ë¸ì˜ Real vs Fake íŒë³„ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "    - ëª¨ë¸ì˜ config.id2label = {0: 'Real', 1: 'Fake'} ê¸°ì¤€ì— ë§ì¶° ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "    - ì¶œë ¥: ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1-score (Fake ê¸°ì¤€)\n",
        "\n",
        "    Parameters:\n",
        "        real_images (list of (str, bytes)): [(íŒŒì¼ëª…, ì´ë¯¸ì§€ bytes)] í˜•íƒœì˜ Real ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸\n",
        "        fake_zip_path (str): Fake ì´ë¯¸ì§€ê°€ ì••ì¶•ë˜ì–´ ìˆëŠ” ZIP íŒŒì¼ ê²½ë¡œ\n",
        "        fake_limit (int): í‰ê°€ì— ì‚¬ìš©í•  ìµœëŒ€ Fake ì´ë¯¸ì§€ ìˆ˜\n",
        "    \"\"\"\n",
        "\n",
        "    all_fake_probs = []   # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ Fake í´ë˜ìŠ¤ (label=1)ì˜ í™•ë¥ \n",
        "    all_labels = []       # ì‹¤ì œ ì •ë‹µ ë¼ë²¨ (0=Real, 1=Fake)\n",
        "    all_names = []        # íŒŒì¼ëª… ì €ì¥\n",
        "\n",
        "    # 1) Real ì´ë¯¸ì§€ ì˜ˆì¸¡ (label=0)\n",
        "    with torch.no_grad():\n",
        "        for name, img_bytes in real_images[:50]:\n",
        "            image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "            inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "            outputs = model(**inputs)\n",
        "            prob_fake = torch.softmax(outputs.logits, dim=1)[0][1].item()  # label=1 (Fake) í™•ë¥ \n",
        "\n",
        "            all_fake_probs.append(prob_fake)\n",
        "            all_labels.append(0)  # Real â†’ label 0\n",
        "            all_names.append(name)\n",
        "            print(f\"[REAL] {name}: prob(Fake) = {prob_fake:.3f}\")\n",
        "\n",
        "    # 2) Fake ì´ë¯¸ì§€ ì˜ˆì¸¡ (label=1)\n",
        "    with zipfile.ZipFile(fake_zip_path, 'r') as zip_ref:\n",
        "        fake_images = [n for n in zip_ref.namelist() if n.endswith(('.jpg', '.png'))][:fake_limit]\n",
        "        with torch.no_grad():\n",
        "            for name in fake_images:\n",
        "                image = Image.open(io.BytesIO(zip_ref.read(name))).convert(\"RGB\")\n",
        "                inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "                outputs = model(**inputs)\n",
        "                prob_fake = torch.softmax(outputs.logits, dim=1)[0][1].item()  # label=1 (Fake) í™•ë¥ \n",
        "\n",
        "                all_fake_probs.append(prob_fake)\n",
        "                all_labels.append(1)  # Fake â†’ label 1\n",
        "                all_names.append(name)\n",
        "                print(f\"[FAKE] {name}: prob(Fake) = {prob_fake:.3f}\")\n",
        "\n",
        "    # 3) Best Threshold íƒìƒ‰ (precision â‰ˆ recall ì¡°ê±´ ê¸°ì¤€)\n",
        "    best_thresh = 0.5\n",
        "    min_diff = float('inf')\n",
        "    for t in np.arange(0.05, 1.0, 0.01):\n",
        "        preds = [1 if p > t else 0 for p in all_fake_probs]  # threshold ê¸°ì¤€ìœ¼ë¡œ Fake ì˜ˆì¸¡\n",
        "        prec = precision_score(all_labels, preds, pos_label=1, zero_division=0)\n",
        "        rec = recall_score(all_labels, preds, pos_label=1, zero_division=0)\n",
        "        diff = abs(prec - rec)\n",
        "        if diff < min_diff:\n",
        "            min_diff = diff\n",
        "            best_thresh = t\n",
        "\n",
        "    # 4) ìµœì¢… ì˜ˆì¸¡ ë° ì„±ëŠ¥ ì¶œë ¥\n",
        "    final_preds = [1 if p > best_thresh else 0 for p in all_fake_probs]  # Fake í™•ë¥ ì´ í¬ë©´ Fakeë¡œ ì˜ˆì¸¡\n",
        "\n",
        "    print(\"\\n--- ì˜ˆì¸¡ ê²°ê³¼ ---\")\n",
        "    for name, prob, label, pred in zip(all_names, all_fake_probs, all_labels, final_preds):\n",
        "        label_str = \"REAL\" if label == 0 else \"FAKE\"\n",
        "        pred_str = \"REAL\" if pred == 0 else \"FAKE\"\n",
        "        print(f\"{name}: GT={label_str}, Pred={pred_str}, prob(Fake)={prob:.3f}\")\n",
        "\n",
        "    acc = accuracy_score(all_labels, final_preds)\n",
        "    prec = precision_score(all_labels, final_preds, pos_label=1, zero_division=0)\n",
        "    rec = recall_score(all_labels, final_preds, pos_label=1, zero_division=0)\n",
        "    f1 = f1_score(all_labels, final_preds, pos_label=1, zero_division=0)\n",
        "\n",
        "    print(f\"\\nBest Threshold: {best_thresh:.2f}\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f} (Fake ê¸°ì¤€)\")\n",
        "    print(f\"Recall   : {rec:.4f} (Fake ê¸°ì¤€)\")\n",
        "    print(f\"F1-score : {f1:.4f} (Fake ê¸°ì¤€)\")"
      ],
      "metadata": {
        "id": "_H4ySHTF3f2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í‰ê°€ ì‹¤í–‰\n",
        "evaluate_real_vs_fake(real_images=xx_real, fake_zip_path=xx_fake_path2)"
      ],
      "metadata": {
        "id": "GVpg_wRKFlvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Threshold: 0.99\n",
        "Accuracy : 0.5000\n",
        "Precision: 0.0000 (Fake ê¸°ì¤€)\n",
        "Recall   : 0.0000 (Fake ê¸°ì¤€)\n",
        "F1-score : 0.0000 (Fake ê¸°ì¤€)"
      ],
      "metadata": {
        "id": "L1N4mrR3vgoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Fine-Tuning"
      ],
      "metadata": {
        "id": "VHZLvRIKwfYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FAKE Nì¥ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "fake_data = load_fake_images(xx_fake_path)\n",
        "dataset = FakeDataset(fake_data, processor)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# í•™ìŠµ ë£¨í”„ ì •ì˜\n",
        "def train_fake(model, loader, epochs=2):\n",
        "    \"\"\"\n",
        "    FAKE ë°ì´í„°ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •(Fine-Tuning)í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            inputs = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} - Loss: {total_loss / len(loader):.4f}\")\n",
        "\n",
        "# Fine-Tuning ì‹œì‘\n",
        "train_fake(model, loader, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st8FfqYtyefB",
        "outputId": "43f9f955-8bd8-461a-f1b1-3074dfac9662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188/188 [00:29<00:00,  6.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188/188 [00:29<00:00,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Loss: 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. ëª¨ë¸ ì €ì¥\n",
        "save_path ê²½ë¡œ ë‚´ë¶€ì— ë‹¤ìŒê³¼ ê°™ì€ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:\n",
        "    \n",
        "    model_fake/\n",
        "    â”œâ”€â”€ config.json                # ëª¨ë¸ êµ¬ì¡° ì •ë³´\n",
        "    â”œâ”€â”€ pytorch_model.bin         # ëª¨ë¸ ê°€ì¤‘ì¹˜ (PyTorch Tensor)\n",
        "    â”œâ”€â”€ preprocessor_config.json  # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê´€ë ¨ ì„¤ì •\n",
        "    â”œâ”€â”€ tokenizer_config.json     # (í…ìŠ¤íŠ¸ ëª¨ë¸ìš© - Vision ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ ì—†ìŒ)\n",
        "    â”œâ”€â”€ special_tokens_map.json   # (í…ìŠ¤íŠ¸ ëª¨ë¸ìš© - Vision ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ ì—†ìŒ)\n",
        "\n",
        "| íŒŒì¼ëª…                                                  | ì„¤ëª…                                         |\n",
        "| ---------------------------------------------------- | ------------------------------------------ |\n",
        "| `pytorch_model.bin`                                  | í•™ìŠµëœ ëª¨ë¸ì˜ **ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°** ì €ì¥ (.bin í˜•ì‹, PyTorch) |\n",
        "| `config.json`                                        | ëª¨ë¸ì˜ êµ¬ì¡° ì •ì˜ (ì˜ˆ: ë ˆì´ì–´ ìˆ˜, hidden size ë“±)        |\n",
        "| `preprocessor_config.json`                           | ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë°©ì‹ ì •ë³´ (resize, normalize ë“±)        |\n",
        "| `tokenizer_config.json`<br>`special_tokens_map.json` | ì£¼ë¡œ í…ìŠ¤íŠ¸ ëª¨ë¸ì—ì„œ ì‚¬ìš©. Vision ëª¨ë¸ì—ì„  ëŒ€ë¶€ë¶„ ìƒì„±ë˜ì§€ ì•ŠìŒ    |\n"
      ],
      "metadata": {
        "id": "mxnF4CN2wno3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ê³¼ processor ì €ì¥\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/Deepfake_Detection/model_fake\"\n",
        "model.save_pretrained(save_path)\n",
        "processor.save_pretrained(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdsUFpIOyy7p",
        "outputId": "5fe0c270-ede9-4358-fe33-33ed74b775c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/Deepfake_Detection/vit_ddim_fake/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Inference (ìµœì¢… í‰ê°€)"
      ],
      "metadata": {
        "id": "joqe3mFawreS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì €ì¥ëœ Fine-tuned ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "processor = AutoImageProcessor.from_pretrained(save_path)\n",
        "model = AutoModelForImageClassification.from_pretrained(save_path).to(\"cuda\").eval()\n",
        "\n",
        "# ìµœì¢… í‰ê°€\n",
        "evaluate_real_vs_fake(real_images=xx_real, fake_zip_path=xx_fake_path2)"
      ],
      "metadata": {
        "id": "JprFQJ2d0cKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Threshold: 0.99\n",
        "Accuracy : 0.8600\n",
        "Precision: 0.7812 (Fake ê¸°ì¤€)\n",
        "Recall   : 1.0000 (Fake ê¸°ì¤€)\n",
        "F1-score : 0.8772 (Fake ê¸°ì¤€)"
      ],
      "metadata": {
        "id": "zM_-boE0v_t8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ê³¼ í•´ì„\n",
        "\n",
        "**ì‚¬ì „í•™ìŠµ ëª¨ë¸ (pretrained)** ê²°ê³¼:\n",
        "- Best Threshold: 0.99\n",
        "- Accuracy : 0.5000\n",
        "- Precision: 0.0000 (FAKE ê¸°ì¤€)\n",
        "- Recall   : 0.0000 (FAKE ê¸°ì¤€)\n",
        "- F1-score : 0.0000 (FAKE ê¸°ì¤€)\n",
        "\n",
        "â†’ ì´ëŠ” ì‚¬ì „í•™ìŠµ ëª¨ë¸ì´ Deepfake (FAKE) ì´ë¯¸ì§€ë¥¼ ì „í˜€ ì¡ì•„ë‚´ì§€ ëª»í–ˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "â†’ thresholdë¥¼ 0.99ë¡œ ë†’ê²Œ ì„¤ì •í•´ë„ í™•ë¥  ì˜ˆì¸¡ì´ ë¯¸ì•½í•˜ì—¬ ì‹¤ì œ FAKE ì´ë¯¸ì§€ë¥¼ REALë¡œ ì˜¤ë¶„ë¥˜í•œ ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "â†’ ì¦‰, ì‹¤ì œ fine-tuningëœ ë°ì´í„°ì™€ ì‚¬ì „í•™ìŠµëœ ë„ë©”ì¸ ê°„ ì°¨ì´ê°€ í¬ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ë‚®ê²Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Fine-tuning** ëª¨ë¸ ê²°ê³¼:\n",
        "- Best Threshold: 0.99\n",
        "- Accuracy : 0.8600\n",
        "- Precision: 0.7812 (FAKE ê¸°ì¤€)\n",
        "- Recall   : 1.0000 (FAKE ê¸°ì¤€)\n",
        "- F1-score : 0.8772 (FAKE ê¸°ì¤€)\n",
        "\n",
        "â†’ fine-tuning ì´í›„ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "â†’ íŠ¹íˆ recall=1.0ì€ ëª¨ë“  FAKE ì´ë¯¸ì§€ë¥¼ ë¹ ì§ì—†ì´ íƒì§€í–ˆë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.\n",
        "\n",
        "â†’ precisionì´ 0.7812ì´ë¯€ë¡œ, FAKEë¡œ ì˜ˆì¸¡í•œ ì´ë¯¸ì§€ ì¤‘ 78%ê°€ ì‹¤ì œ FAKEì˜€ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "ZLIecbZuTY6p"
      }
    }
  ]
}