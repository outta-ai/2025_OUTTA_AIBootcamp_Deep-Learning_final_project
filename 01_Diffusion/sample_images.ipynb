{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["m7xNuCV6XVIM","wAL1dpULXe-V","u8fIxWYeYTfN","BS93rvu-Xtzd"],"authorship_tag":"ABX9TyMGrfwNBRt4KG0g75xHN9cg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setting"],"metadata":{"id":"m7xNuCV6XVIM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qS6aSM3RP3LL"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from tqdm.auto import tqdm\n","import math"],"metadata":{"id":"Oje9wTsOXU1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.random.seed(SEED)\n","torch.manual_seed(SEED)"],"metadata":{"id":"5NfORMRBlkhB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"wAL1dpULXe-V"}},{"cell_type":"code","source":["# train에서 구현한 model 코드 그대로 사용하시면 됩니다."],"metadata":{"id":"ohL9QifTXUx5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get alphas_cumprod"],"metadata":{"id":"u8fIxWYeYTfN"}},{"cell_type":"code","source":["def get_beta_alpha_linear(beta_start=0.0001, beta_end=0.02, num_timesteps=1000):\n","    # DDPM 학습 및 샘플링에 쓰일 alpha, beta, alphas_cumprod 반환\n","    # Train에서 쓰인 함수와 정확히 같습니다.\n","\n","    betas = np.linspace(beta_start, beta_end, num_timesteps, dtype=np.float32)\n","    betas = torch.tensor(betas)\n","    alphas = 1.0 - betas\n","    alphas_cumprod = torch.cumprod(alphas, dim=0)\n","\n","    return betas, alphas, alphas_cumprod"],"metadata":{"id":"deIcETNuYWA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Sampling"],"metadata":{"id":"BS93rvu-Xtzd"}},{"cell_type":"code","source":["# sample에서 구현한 model 코드 그대로 사용하시면 됩니다."],"metadata":{"id":"rk3zMv1RXUu_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save Images"],"metadata":{"id":"IVuN5PQqO1MF"}},{"cell_type":"code","source":["def create_batch_images(count):\n","    with torch.no_grad():\n","        num_saved_images = 0\n","        # num_saved_images가 count보다 커지면 저장이 종료됩니다.\n","        while num_saved_images<=count:\n","            # B*3*64*64 크기의 tensor가 samples에 담기게 됩니다.\n","            samples = sample_ddim(model, shape=(batch_size, 3, image_size, image_size), alphas_cumprod=alphas_cumprod, device=device, ddim_steps=200, eta=0.0)\n","            # batch의 각 3*64*64 이미지를 PIL Image로 변환 후 저장됩니다.\n","            for j in range(batch_size):\n","                img = samples[j]\n","                img = img.numpy()\n","                img = np.transpose(img, (1, 2, 0))\n","                img = (img + 1.0) / 2.0\n","                img = np.clip(img, 0, 1)\n","                img = (img * 255).astype(np.uint8)\n","                pil_img = Image.fromarray(img)\n","                pil_img.save(\n","                    f'/content/fake/{num_saved_images+j}.jpg',\n","                    format='JPEG',\n","                    quality=85,\n","                    optimize=True,\n","                    progressive=True\n","                )\n","            num_saved_images += batch_size"],"metadata":{"id":"QZFXlOyYO2ih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 샘플링한 이미지들이 저장될 Colab 로컬 VM의 폴더를 생성합니다.\n","# 이후 폴더를 압축하여 gdrive에 옮깁니다.\n","!mkdir /content/fake"],"metadata":{"id":"P9eNEV2jRa32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","_, _, alphas_cumprod = get_beta_alpha_linear()\n","alphas_cumprod = alphas_cumprod.to(device)\n","\n","# 학습할 때와 같은 batch_size 사용 권장\n","batch_size = 64\n","# image_size는 고정해주세요.\n","image_size = 64\n","\n","# train할 때 저장한 모델 파라미터 pt파일 불러오기\n","model = DDPMModel().to(device)\n","model_path = ''\n","checkpoint = torch.load(model_path, map_location=device)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","print(f'Model is loaded')\n","\n","model.eval()\n","\n","# 샘플링하고 싶은 이미지 수 (정확하게 3000장이 샘플링 되지는 않습니다.)\n","count = 3000\n","create_batch_images(count)"],"metadata":{"id":"0T3YfdR3XUsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 샘플링한 이미지가 저장되어 있는 디렉토리로 이동합니다.\n","%cd /content/fake\n","# gdrive의 디렉토리에 압축파일을 저장합니다.\n","!zip -r /content/sample_directory/DDIM_sampled_images.zip ."],"metadata":{"id":"lQLXiWjBRovb"},"execution_count":null,"outputs":[]}]}