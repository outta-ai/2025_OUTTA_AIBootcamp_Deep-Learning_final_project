{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prtI2y6mrSy9"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer.ipynb \"\"\"\n",
    "\n",
    "# import\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0pBwAe5rYp0"
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LAaFb__rXnb"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer \"\"\"\n",
    "\n",
    "# Generator와 Discriminator 학습 + fade-in 기법 적용\n",
    "class Trainer():\n",
    "    def __init__(self, steps, device, train_loader, val_loader, checkpoint_path=None):\n",
    "      # Progressive 단계 수\n",
    "      self.steps = steps\n",
    "      self.device = device\n",
    "      self.train_loader = train_loader\n",
    "      self.val_loader = val_loader\n",
    "\n",
    "      # Generator & Discriminator 모델 -> device\n",
    "      self.generator = Generator(steps).to(device)\n",
    "      self.discriminator = Discriminator(steps).to(device)\n",
    "\n",
    "      # 이진 분류용 loss function -> 진짜 vs 가짜\n",
    "      self.criterion = nn.BCELoss()\n",
    "\n",
    "      # Optimizer: Adam\n",
    "      self.g_opt = Adam(self.generator.parameters(), lr=0.003, betas=(0.0,0.99))\n",
    "      self.d_opt = Adam(self.discriminator.parameters(), lr=0.001, betas=(0.0,0.99))\n",
    "\n",
    "      # ---fade-in 제어---\n",
    "      self.alpha = 0\n",
    "      # 한 epoch 동안 alpha가 0~1이 되도록 조정\n",
    "      self.alpha_gap = 1 / (len(train_loader) * 5) # 총 5 epoch동안 전환\n",
    "\n",
    "      self.final_sample_dir = \"/content/drive/MyDrive/ProGAN/Final_images\" # 최종 생성 이미지 저장 위치 - 변경 가능\n",
    "      os.makedirs(self.final_sample_dir, exist_ok=True)\n",
    "\n",
    "      self.epoch_image_dir = \"/content/drive/MyDrive/ProGAN/epoch_images\" # 각 epoch 별 이미지 저장 위치 - 변경 가능\n",
    "      os.makedirs(self.epoch_image_dir, exist_ok=True)\n",
    "\n",
    "      self.checkpoint_dir = \"/content/drive/MyDrive/ProGAN/checkpoints\" # checkpoint 저장 위치 - 변경 가능\n",
    "      os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "      # ---Sampling용 고정 noise---\n",
    "      # 매 epoch마다 같은 z 입력 -> 생성 결과 변화 비교\n",
    "      self.test_z = torch.randn(1, 128, 1, 1, device=self.device)\n",
    "      self.test_z_last = torch.randn(50, 128, 1, 1, device=self.device)\n",
    "\n",
    "      self.start_epoch = 0\n",
    "      self.history = {'g_train': [], 'd_train': [], 'g_val': [], 'd_val': []}\n",
    "\n",
    "      if checkpoint_path is not None:\n",
    "        self._load_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Save checkpoint\n",
    "    def _save_checkpoint(self, epoch):\n",
    "      path = os.path.join(self.checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\") # Google Drive 내에 저장하는 것을 추천드립니다.(런타임 끊기는 것을 대비)\n",
    "      torch.save({\n",
    "          'epoch': epoch,\n",
    "          'generator': self.generator.state_dict(),\n",
    "          'discriminator': self.discriminator.state_dict(),\n",
    "          'g_opt': self.g_opt.state_dict(),\n",
    "          'd_opt': self.d_opt.state_dict(),\n",
    "          'alpha': self.alpha,\n",
    "          'history': self.history\n",
    "      }, path)\n",
    "      print(f\"Checkpoint saved: {path}\")\n",
    "\n",
    "\n",
    "    # Load checkpoint\n",
    "    def _load_checkpoint(self, path):\n",
    "      checkpoint = torch.load(path)\n",
    "      self.generator.load_state_dict(checkpoint['generator'])\n",
    "      self.discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "      self.g_opt.load_state_dict(checkpoint['g_opt'])\n",
    "      self.d_opt.load_state_dict(checkpoint['d_opt'])\n",
    "      self.alpha = checkpoint['alpha']\n",
    "      self.start_epoch = checkpoint['epoch'] + 1\n",
    "      self.history = checkpoint['history']\n",
    "      print(f\"Resuming training from epoch {self.start_epoch}\")\n",
    "\n",
    "\n",
    "    # 매 epoch 후 고정 노이즈로 이미지 생성 및 저장\n",
    "    def save_epoch_image(self, epoch):\n",
    "      # BatchNorm, Dropout 비활성화\n",
    "      self.generator.eval()\n",
    "      with torch.no_grad():\n",
    "        fake = self.generator(self.test_z)\n",
    "        save_image(fake[0], f\"{self.epoch_image_dir}/epoch_{epoch:03d}.png\", normalize=True, value_range=(-1, 1))\n",
    "\n",
    "    # 마지막 epoch 최종 이미지 생성 및 저장\n",
    "    def save_last_epoch_image(self, epoch):\n",
    "      self.generator.eval()\n",
    "      with torch.no_grad():\n",
    "        fake = self.generator(self.test_z_last)\n",
    "        for i in range(fake.size(0)):\n",
    "          save_image(fake[i], f\"{self.final_sample_dir}/epoch_{epoch:03d}_sample_{i:02d}.png\", normalize=True, value_range=(-1, 1))\n",
    "\n",
    "\n",
    "    # 한 epoch동안 Generator와 Discriminator 학습\n",
    "    def train_epoch(self):\n",
    "      self.generator.train()\n",
    "      self.discriminator.train()\n",
    "      g_loss_avg = 0\n",
    "      d_loss_avg = 0\n",
    "\n",
    "      for real in self.train_loader:\n",
    "        real = real.to(self.device)\n",
    "\n",
    "        # batch size\n",
    "        bs = real.size(0)\n",
    "        real_lbl = torch.full((bs, 1), 0.9, device=self.device)\n",
    "        fake_lbl = torch.full((bs, 1), 0.1, device=self.device)\n",
    "\n",
    "        # ---Discriminator Train---\n",
    "        # 가짜 이미지 생성\n",
    "        z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "        fake = self.generator(z)\n",
    "\n",
    "        # 진짜/가짜 판별\n",
    "        d_fake = self.discriminator(fake.detach(), self.alpha)\n",
    "        d_real = self.discriminator(real, self.alpha)\n",
    "\n",
    "        # loss 계산 - 진짜 = 1, 가짜 = 0\n",
    "        d_loss = self.criterion(d_fake, fake_lbl) + self.criterion(d_real, real_lbl)\n",
    "\n",
    "        # 역전파 & parameter 업데이트\n",
    "        self.d_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.d_opt.step()\n",
    "\n",
    "        # 두 loss의 평균값\n",
    "        d_loss_avg += d_loss.item()/2\n",
    "\n",
    "        # ---Generator Train---\n",
    "        # 새로운 노이즈로 가짜 이미지 생성\n",
    "        for _ in range(2):\n",
    "          z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "          fake = self.generator(z)\n",
    "\n",
    "          # Discriminator가 가짜를 진짜로 판단하도록 유도\n",
    "          g_loss = self.criterion(self.discriminator(fake, self.alpha), real_lbl)\n",
    "\n",
    "          # 역전파 & parameter 업데이트\n",
    "          self.g_opt.zero_grad()\n",
    "          g_loss.backward()\n",
    "          self.g_opt.step()\n",
    "          g_loss_avg += g_loss.item()\n",
    "\n",
    "        # fade-in 비율 업데이트 - block 간 부드러운 전환\n",
    "        self.alpha = min(1, self.alpha + self.alpha_gap)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "      # epcoh 별 평균 loss 반환\n",
    "      return g_loss_avg/len(self.train_loader), d_loss_avg/len(self.train_loader)\n",
    "\n",
    "\n",
    "    def valid_epoch(self):\n",
    "      # 한 epoch 동안 Generator/Discriminator의 validation loss 계산\n",
    "      self.generator.eval()\n",
    "      self.discriminator.eval()\n",
    "      g_loss_avg = 0\n",
    "      d_loss_avg = 0\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for real in self.val_loader:\n",
    "          real = real.to(self.device)\n",
    "          bs = real.size(0)\n",
    "          real_lbl = torch.full((bs, 1), 0.9, device=self.device)\n",
    "          fake_lbl = torch.full((bs, 1), 0.1, device=self.device)\n",
    "\n",
    "          # Discriminator 검증\n",
    "          z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "          fake = self.generator(z)\n",
    "          d_fake = self.discriminator(fake, self.alpha)\n",
    "          d_real = self.discriminator(real, self.alpha)\n",
    "          d_loss_avg += (self.criterion(d_fake, fake_lbl) + self.criterion(d_real, real_lbl)).item() / 2\n",
    "\n",
    "          # Generator 검증\n",
    "          z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "          fake = self.generator(z)\n",
    "          g_loss_avg += self.criterion(self.discriminator(fake, self.alpha), real_lbl).item()\n",
    "\n",
    "      return g_loss_avg/len(self.val_loader), d_loss_avg/len(self.val_loader)\n",
    "\n",
    "\n",
    "    # 지정된 epoch 수만큼 학습 및 검증을 수행하고 epoch마다 이미지 저장\n",
    "    def run(self, epochs):\n",
    "      for epoch in range(self.start_epoch, epochs):\n",
    "        # 학습 & validation loss 계산\n",
    "        g_t, d_t = self.train_epoch()\n",
    "        g_v, d_v = self.valid_epoch()\n",
    "        self.history['g_train'].append(g_t)\n",
    "        self.history['d_train'].append(d_t)\n",
    "        self.history['g_val'].append(g_v)\n",
    "        self.history['d_val'].append(d_v)\n",
    "\n",
    "        # loss log 출력\n",
    "        print(f\"Epoch {epoch}: G_loss {g_t:.4f}/{g_v:.4f}, D_loss {d_t:.4f}/{d_v:.4f}\")\n",
    "\n",
    "        # epoch별 생성 이미지 저장\n",
    "        self.save_epoch_image(epoch)\n",
    "        self._save_checkpoint(epoch)\n",
    "\n",
    "        # 마지막 epoch -> 50개 개별 이미지도 저장\n",
    "        if epoch == epochs - 1:\n",
    "          self.save_last_epoch_image(epoch)\n",
    "          self._save_checkpoint(epoch)\n",
    "\n",
    "      return self.history"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
