{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0PKlvcwousA"
      },
      "source": [
        "## Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUEy3UJro2X7"
      },
      "outputs": [],
      "source": [
        "\"\"\" Evaluate.ipynb \"\"\"\n",
        "\n",
        "# Colab Drive Mount: 결과물을 내 드라이브에 저장하거나 불러오기 위해 필요\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OtgDqYEjo2bi"
      },
      "outputs": [],
      "source": [
        "# Google Drive에서 데이터셋 불러오기\n",
        "!cp /content/drive/MyDrive/img_align_celeba.zip /content/ # 데이터 저장 위치를 작성\n",
        "\n",
        "!unzip -q /content/drive/MyDrive/img_align_celeba.zip -d /content/data/ # 데이터 저장 위치 작성\n",
        "\n",
        "data_dir = '/content/data/img_align_celeba'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV758clCo5uw"
      },
      "source": [
        "## Import / Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jb88LapROlP"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install lpips\n",
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "te-ga9OqUsW5"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from pytorch_fid import fid_score\n",
        "import lpips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UUAJzlBLUwMY"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCO1eFR9pEMR"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VZl5lueyUwH9"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset\n",
        "class SingleImageDataset(Dataset):\n",
        "  def __init__(self, folder, transform=None):\n",
        "    self.paths = sorted([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.png', '.jpg'))])\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.paths[idx]).convert('RGB')\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img, self.paths[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fVbCd3i0Y2mI"
      },
      "outputs": [],
      "source": [
        "gen_folder = '/content/drive/MyDrive/ProGAN/Final_images' # 최종 생성 이미지\n",
        "real_folder = '/content/data/img_align_celeba'\n",
        "sampled_folder = '/content/data/real_celebA_sampled'\n",
        "os.makedirs(sampled_folder, exist_ok=True)\n",
        "\n",
        "# 학습에 사용하지 않은 인덱스에서 50장 추출\n",
        "unused_idx_path = '/content/drive/MyDrive/ProGAN/unused_indices_for_eval.npy'\n",
        "unused_indices = np.load(unused_idx_path)\n",
        "random.seed(42)\n",
        "sample_indices = random.sample(list(unused_indices), 50)\n",
        "\n",
        "# 이미지 복사\n",
        "real_imgs = sorted([f for f in os.listdir(real_folder) if f.endswith('.jpg')])\n",
        "for i, idx in enumerate(sample_indices):\n",
        "  fname = real_imgs[idx]\n",
        "  src = os.path.join(real_folder, fname)\n",
        "  dst = os.path.join(sampled_folder, f\"real_{i:02d}.jpg\")\n",
        "  os.system(f'cp \"{src}\" \"{dst}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbJJ-y7jo_Mh"
      },
      "source": [
        "## Lpips metric / Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDjSTWR8Y-tL"
      },
      "outputs": [],
      "source": [
        "# Lpips metric\n",
        "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "lpips_fn.eval()\n",
        "\n",
        "lpips_tf = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N5Ken-HKySI_"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 준비\n",
        "gen_ds = SingleImageDataset(gen_folder, transform=lpips_tf)\n",
        "real_ds = SingleImageDataset(sampled_folder, transform=lpips_tf)\n",
        "\n",
        "N = min(len(gen_ds), len(real_ds))\n",
        "gen_ds = Subset(gen_ds, list(range(N)))\n",
        "real_ds = Subset(real_ds, list(range(N)))\n",
        "\n",
        "gen_loader = DataLoader(gen_ds, batch_size=1, shuffle=False)\n",
        "real_loader = DataLoader(real_ds, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qZqNNUspHKr"
      },
      "source": [
        "## LPIPS 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2nEcdRTZP3F"
      },
      "outputs": [],
      "source": [
        "# LPIPS 평가\n",
        "total_lpips = []\n",
        "with torch.no_grad():\n",
        "  for (g_img, _), (r_img, _) in zip(gen_loader, real_loader):\n",
        "    g_img = g_img.to(device)\n",
        "    r_img = r_img.to(device)\n",
        "    dist = lpips_fn(g_img, r_img)\n",
        "    total_lpips.append(dist.item())\n",
        "\n",
        "lpips_scores = np.array(total_lpips)\n",
        "\n",
        "print(f\"Evaluated {N} pairs\")\n",
        "print(f\"Mean LPIPS: {lpips_scores.mean():.4f}\")\n",
        "print(f\"Median LPIPS: {np.median(lpips_scores):.4f}\")\n",
        "print(f\"Std LPIPS: {lpips_scores.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP8YGgEbpKAd"
      },
      "source": [
        "## FID 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1CWuJqnZa5s"
      },
      "outputs": [],
      "source": [
        "# FID 평가\n",
        "fid_value = fid_score.calculate_fid_given_paths(\n",
        "    [sampled_folder, gen_folder],\n",
        "    batch_size=50,\n",
        "    device=device,\n",
        "    dims=2048\n",
        ")\n",
        "\n",
        "print(f\"FID Score: {fid_value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
