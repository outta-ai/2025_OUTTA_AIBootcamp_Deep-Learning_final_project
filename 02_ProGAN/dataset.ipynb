{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0OLJp68w2T8"
      },
      "outputs": [],
      "source": [
        "\"\"\" dataset.ipynb \"\"\"\n",
        "\n",
        "# import\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive\n",
        "!cp /content/drive/MyDrive/img_align_celeba.zip /content/ # 데이터 저장 위치를 작성\n",
        "\n",
        "!unzip -q /content/drive/MyDrive/img_align_celeba.zip -d /content/data/ # 데이터 저장 위치 작성\n",
        "\n",
        "data_dir = '/content/data/img_align_celeba'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee1HWeutxzJE"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameter\n",
        "batch_size = 16\n",
        "sample_size = 30000\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWI5BN66zoqu"
      },
      "outputs": [],
      "source": [
        "# Transform 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(178),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# CelebA 데이터셋\n",
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, img_dir, transform=None):\n",
        "    self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")))\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = Image.open(self.img_paths[idx]).convert(\"RGB\")\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    return image\n",
        "\n",
        "# Dataset 로딩\n",
        "full_dataset = CelebADataset(data_dir, transform=transform)\n",
        "full_indices = list(range(len(full_dataset)))\n",
        "\n",
        "# 30000장 샘플링\n",
        "sampled_count = min(sample_size, len(full_dataset))\n",
        "random.seed(seed)\n",
        "sampled_indices = random.sample(full_indices, sampled_count)\n",
        "np.save('/content/drive/MyDrive/ProGAN/train_indices.npy', sampled_indices)\n",
        "\n",
        "subset_dataset = Subset(full_dataset, sampled_indices)\n",
        "\n",
        "# 로딩 속도 확인\n",
        "load_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "start = time.time()\n",
        "for _ in tqdm(load_loader, desc=\"Loading 30000 images\"): pass\n",
        "print(f\"Loaded {sampled_count} images in {(time.time()-start):.2f}s\")\n",
        "\n",
        "# Train/Val 분할\n",
        "train_img = int(0.8 * sampled_count)\n",
        "val_img = sampled_count - train_img\n",
        "train_ds, val_ds = random_split(subset_dataset, [train_img, val_img])\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# 평가용 데이터셋에서 학습에 사용된 인덱스를 제외한 나머지를 저장 - evaluate에서 사용\n",
        "unused_indices = list(set(full_indices) - set(sampled_indices))\n",
        "np.save('/content/drive/MyDrive/ProGAN/unused_indices_for_eval.npy', unused_indices)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
