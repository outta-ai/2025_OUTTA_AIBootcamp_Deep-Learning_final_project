{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFWv66ViRK3K"
      },
      "outputs": [],
      "source": [
        "\"\"\" model.ipynb \"\"\"\n",
        "\n",
        "# import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fap0l5VrRQ3N"
      },
      "source": [
        "## Channel List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcNe2WiaRTK2"
      },
      "outputs": [],
      "source": [
        "# 채널 리스트 / steps\n",
        "channel_list = [128, 128, 128, 128, 64]\n",
        "steps = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jy-oiofRV8L"
      },
      "source": [
        "## WSConv2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW-yF6kLRYf_"
      },
      "outputs": [],
      "source": [
        "\"\"\" WSConv2d \"\"\"\n",
        "\n",
        "class WSConv2d(nn.Module):\n",
        "  # 입력 channel 수, 출력 channel 수, kernel 크기, stride(이동폭), padding(경계 처리), scale 보정 계수\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2):\n",
        "    super().__init__()\n",
        "\n",
        "    # 기본 Conv2d layer 생성\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    # Scale 계산\n",
        "    self.scale = (gain / (in_channels * kernel_size ** 2)) ** 0.5\n",
        "\n",
        "    # Bias를 따로 저장, conv layer에서는 bias 제거\n",
        "    self.bias = self.conv.bias\n",
        "    self.conv.bias = None\n",
        "\n",
        "    # He 초기화 기준 -> weight/bias 초기화\n",
        "    # conv.weight: 정규 분포 샘플링\n",
        "    # bias: 모두 0으로 초기화\n",
        "    nn.init.normal_(self.conv.weight)\n",
        "    nn.init.zeros_(self.bias)\n",
        "\n",
        "\n",
        "\n",
        "  # 입력값 * scale -> weight scaling 효과\n",
        "  def forward(self, x):\n",
        "\n",
        "    # bias는 channel별로 reshape후 더함\n",
        "    out = self.conv(x * self.scale) + self.bias.view(1, -1, 1, 1)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2qrGb4WRzIq"
      },
      "source": [
        "## PixelNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwEzO8SgR1su"
      },
      "outputs": [],
      "source": [
        "\"\"\" PixelNorm \"\"\"\n",
        "\n",
        "class PixelNorm(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # eps -> 분모에 사용\n",
        "    self.eps = 1e-8\n",
        "\n",
        "\n",
        "  # 각 픽셀마다 벡터의 크기를 1로 정규화\n",
        "  # sqrt(mean+eps)로 pixel별 norm 산출\n",
        "  # x를 norm으로 나눠 픽셀 벡터 크기 = 1로 정규화\n",
        "  def forward(self, x):\n",
        "    return x / torch.sqrt(torch.mean(x**2, dim=1, keepdim=True) + self.eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5AhdyIrSWVQ"
      },
      "source": [
        "## UpDownSampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EYWqPt-SYNC"
      },
      "outputs": [],
      "source": [
        "\"\"\" Up/Down Sampling \"\"\"\n",
        "\n",
        "class UpDownSampling(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super().__init__()\n",
        "\n",
        "    # scale_factor: 배율\n",
        "    self.size = size\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # 최근접 보간 - 해상도 전환 시 빠르고 단순한 연산 수행\n",
        "    return F.interpolate(x, scale_factor=self.size, mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m273HuOGSoay"
      },
      "source": [
        "## MinibatchStd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBOtA2NMSp_3"
      },
      "outputs": [],
      "source": [
        "\"\"\" MinibatchStd \"\"\"\n",
        "\n",
        "# Batch 내 통계량 추가 -> 서로 다른 샘플 간 변별력 상승\n",
        "class MinibatchStd(nn.Module):\n",
        "  def forward(self, x):\n",
        "    bs, _, h, w = x.size()\n",
        "\n",
        "    # Channel별 픽셀 표준편차 계산 -> 전체 평균 -> (bsx1xhxw) 크기로 복제\n",
        "    std = torch.std(x, dim=0).mean().repeat(bs, 1, h, w)\n",
        "\n",
        "    # 원본 feature map에 std channel을 추가 -> 미세한 차이 학습 가능\n",
        "    return torch.cat([x, std], dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8xBijS0Syzo"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBM7OVXwS0er"
      },
      "outputs": [],
      "source": [
        "\"\"\" Generator Block \"\"\"\n",
        "\n",
        "# 해상도를 2배씩 늘려 특징을 점진적으로 확장\n",
        "class GeneratorConvBlock(nn.Module):\n",
        "  def __init__(self, step, scale_size):\n",
        "    super().__init__()\n",
        "\n",
        "    # 2x upsampling layer: 크기를 scale_size배로 증가\n",
        "    self.up = UpDownSampling(scale_size)\n",
        "\n",
        "    # 2번의 WSConv + LeakyReLU + PixelNorm 반복\n",
        "    # 첫 번째 WSConv2d: 채널 수를 이전 단계 -> 현재 단계로 변환\n",
        "    self.conv1 = WSConv2d(channel_list[step-1], channel_list[step])\n",
        "\n",
        "    # 두 번째 WSConv2d: 같은 채널 수 유지하며 추가 특징 학습\n",
        "    self.conv2 = WSConv2d(channel_list[step], channel_list[step])\n",
        "\n",
        "    # LeakyReLU 적용 -> 학습 안정화\n",
        "    self.lrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    # PixelNorm: 픽셀 단위 정규화를 통한 학습 안정화\n",
        "    self.pn = PixelNorm()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Upsampling -> 해상도 x2\n",
        "    x = self.up(x)\n",
        "\n",
        "    # 첫 번째 Conv2 -> LeakyReLU -> PixelNorm\n",
        "    x = self.lrelu(self.conv1(x))\n",
        "    x = self.pn(x)\n",
        "\n",
        "    # 두 번째 Conv2 -> LeakyReLU -> PixelNorm\n",
        "    x = self.lrelu(self.conv2(x))\n",
        "    x = self.pn(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\" Generator Structure \"\"\"\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, steps):\n",
        "    super().__init__()\n",
        "    self.steps = steps\n",
        "\n",
        "    # --- 초기 블록: 4x4 ---\n",
        "    # PixelNorm: 입력 z 정규화\n",
        "    # ConvTranspose2d: 채널 list[0] -> 채널_list[0], kernel 4x4 -> 4x4 map 생성\n",
        "    # LeakyReLU -> WSConv2d -> LeakyReLU -> PixelNorm\n",
        "    self.init = nn.Sequential(\n",
        "        PixelNorm(),\n",
        "        nn.ConvTranspose2d(channel_list[0], channel_list[0], 4, 1, 0),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        WSConv2d(channel_list[0], channel_list[0]),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        PixelNorm()\n",
        "    )\n",
        "\n",
        "    # --- Progressive Block ---\n",
        "    # init 블록 뒤 -> step=1부터 steps까지 GeneratorConvBlock 쌓기\n",
        "    # 각 block이 해상도를 2배씩 증가시키며 특징 확장\n",
        "    self.prog_blocks = nn.ModuleList([self.init] + [GeneratorConvBlock(step, 2) for step in range(1, steps+1)])\n",
        "\n",
        "    # --- toRGB layer ---\n",
        "    # 마지막 feature map을 RGB 이미지로 변환 & kernel 크기 1x1로 channel 변환만 수행\n",
        "    self.toRGB = WSConv2d(channel_list[steps], 3, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\n",
        "  def forward(self, z):\n",
        "    out = z\n",
        "\n",
        "    # 초기 4x4 block\n",
        "    out = self.prog_blocks[0](out)\n",
        "\n",
        "    # 점진적 해상도 증가 블록 순차 적용(해상도 x2 -> feature map 확장)\n",
        "    for block in self.prog_blocks[1:]:\n",
        "      out = block(out)\n",
        "\n",
        "    # toRGB: 마지막 feature map을 RGB 이미지로 변환\n",
        "    return self.toRGB(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ze0hoc3npLb"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79-MiHSunqyB"
      },
      "outputs": [],
      "source": [
        "\"\"\" Discriminator Block \"\"\"\n",
        "\n",
        "# 해상도를 단계별로 줄이며 특징 추출\n",
        "class DiscriminatorConvBlock(nn.Module):\n",
        "    def __init__(self, step):\n",
        "      super().__init__()\n",
        "\n",
        "      # ---각 해상도별 fromRGB layer와 block을 역순으로 쌓음---\n",
        "      # 첫 번째 WSConv2d: 같은 채널 수 유지하며 nonlinear activation 전 특징 추출\n",
        "      self.conv1 = WSConv2d(channel_list[step], channel_list[step])\n",
        "\n",
        "      # 두 번째 WSConv2d: 이전 단계 채널 수로 줄이면서 세밀한 특징 학습\n",
        "      self.conv2 = WSConv2d(channel_list[step], channel_list[step-1])\n",
        "\n",
        "      # AvgPool: 해상도 절반으로 줄이는 downsampling\n",
        "      self.down = nn.AvgPool2d(2,2)\n",
        "\n",
        "      # LeakyReLU 적용 -> 학습 안정화\n",
        "      self.lrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self,x):\n",
        "      # conv1 -> LeakyReLU\n",
        "      x = self.lrelu(self.conv1(x))\n",
        "\n",
        "      # conv2 -> LeakyReLU\n",
        "      x = self.lrelu(self.conv2(x))\n",
        "\n",
        "      # 해상도 절반으로 축소\n",
        "      return self.down(x)\n",
        "\n",
        "\n",
        "\"\"\" Discriminator Structure \"\"\"\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, steps):\n",
        "      super().__init__()\n",
        "      self.steps=steps\n",
        "\n",
        "      # 각 해상도별 fromRGB layer를 list 순서대로 저장\n",
        "      self.fromrgb_layers = nn.ModuleList()\n",
        "\n",
        "      # 단계별 Conv block을 순서대로 저장\n",
        "      self.prog_blocks = nn.ModuleList()\n",
        "\n",
        "      # 높은 해상도 -> 낮은 해상도 순으로 layer 구성\n",
        "      for s in range(steps, 0, -1):\n",
        "\n",
        "        # RGB 이미지를 channel_list[s] 만큼의 feature map으로 변환\n",
        "        self.fromrgb_layers.append(WSConv2d(3, channel_list[s], 1, 1, 0))\n",
        "\n",
        "        # 해당 해상도 단계의 ConvBlock 추가\n",
        "        self.prog_blocks.append(DiscriminatorConvBlock(s))\n",
        "\n",
        "      # 최종 해상도용 fromRGB layer\n",
        "      self.fromrgb_layers.append(WSConv2d(3,channel_list[0], 1, 1, 0))\n",
        "\n",
        "      # 최종 Discriminator block: Minibatch -> 3x3 conv -> 4x4 conv -> 1x1 conv -> Sigmoid\n",
        "      self.prog_blocks.append(nn.Sequential(\n",
        "          # 배치 표준편차 channel 추가\n",
        "          MinibatchStd(),\n",
        "          WSConv2d(channel_list[0]+1, channel_list[0], 3, 1, 1),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          WSConv2d(channel_list[0], channel_list[0], 4, 1, 0),\n",
        "          nn.LeakyReLU(0.2),\n",
        "          # 최종 실수 scalar값 출력\n",
        "          WSConv2d(channel_list[0], 1, 1, 1, 0),\n",
        "          # 0~1 확률값으로 변환\n",
        "          nn.Sigmoid()\n",
        "      ))\n",
        "\n",
        "      # 추가 downsample layer 및 활성화\n",
        "      self.down = nn.AvgPool2d(2,2)\n",
        "      self.lrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "    # fade-in\n",
        "    def fade_in(self, alpha, down, cur):\n",
        "      # down: 이전 해상도의 특징 / cur: 현재 해상도의 특징 / alpha 비율로 보간 -> 점진적 성장 학습 안정화\n",
        "      return alpha*cur + (1-alpha)*down\n",
        "\n",
        "\n",
        "    def forward(self, x, alpha):\n",
        "      # 현재 해상도에서부터 처리 시작: fromRGB -> LeakyReLU\n",
        "      out = self.lrelu(self.fromrgb_layers[0](x))\n",
        "\n",
        "      # 현재 단계 = 0인 경우 -> 최종 판별 block으로 이동\n",
        "      if self.steps==0:\n",
        "          return self.prog_blocks[-1](out).view(out.size(0), -1)\n",
        "\n",
        "      # 이전 해상도용 특징: Downsampling -> fromRGB -> LeakyReLU\n",
        "      down = self.lrelu(self.fromrgb_layers[1](self.down(x)))\n",
        "\n",
        "      # 현재 해상도 ConvBlock 적용\n",
        "      out = self.prog_blocks[0](out)\n",
        "\n",
        "      # fade-in 보간 적용\n",
        "      out = self.fade_in(alpha, down, out)\n",
        "\n",
        "      # 남아있는 모든 ConvBlock 연쇄 적용\n",
        "      for i in range(1, self.steps+1):\n",
        "        out = self.prog_blocks[i](out)\n",
        "\n",
        "      # 최종 Discriminator 출력\n",
        "      return out.view(out.size(0), -1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
