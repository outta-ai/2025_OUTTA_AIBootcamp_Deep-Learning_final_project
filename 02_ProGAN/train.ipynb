{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Sxlc50vuIe"
   },
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKUqCV1bvv0S"
   },
   "outputs": [],
   "source": [
    "\"\"\" Train.ipynb \"\"\"\n",
    "\n",
    "# Colab Drive Mount: 결과물을 내 드라이브에 저장하거나 불러오기 위해 필요\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qgAi1Wfvwc6"
   },
   "outputs": [],
   "source": [
    "# Google Drive에서 데이터셋 불러오기\n",
    "!cp /content/drive/MyDrive/img_align_celeba.zip /content/ # 데이터 저장 위치를 작성\n",
    "\n",
    "!unzip -q /content/drive/MyDrive/img_align_celeba.zip -d /content/data/ # 데이터 저장 위치 작성\n",
    "\n",
    "data_dir = '/content/data/img_align_celeba'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk7mjX7LvzIQ"
   },
   "source": [
    "## Import / Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wytcX7Yjv1UH"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset, TensorDataset, ConcatDataset\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQGpwR-Jv4hU"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "dataset.ipynb 파일 내 코드를 사용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjocOhPbv6We"
   },
   "outputs": [],
   "source": [
    "# Parameter\n",
    "batch_size = 16\n",
    "sample_size = 30000\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOVMhK0zwTdZ"
   },
   "outputs": [],
   "source": [
    "\"\"\" 데이터 처리 \"\"\"\n",
    "# Transform 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(178),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# CelebA 데이터셋\n",
    "class CelebADataset(Dataset):\n",
    "  def __init__(self, img_dir, transform=None):\n",
    "    self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")))\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.img_paths)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = Image.open(self.img_paths[idx]).convert(\"RGB\")\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image\n",
    "\n",
    "# Dataset 로딩\n",
    "full_dataset = CelebADataset(data_dir, transform=transform)\n",
    "full_indices = list(range(len(full_dataset)))\n",
    "\n",
    "# 30000장 샘플링\n",
    "sampled_count = min(sample_size, len(full_dataset))\n",
    "random.seed(seed)\n",
    "sampled_indices = random.sample(full_indices, sampled_count)\n",
    "np.save('/content/drive/MyDrive/ProGAN/train_indices.npy', sampled_indices)\n",
    "\n",
    "subset_dataset = Subset(full_dataset, sampled_indices)\n",
    "\n",
    "# 로딩 속도 확인\n",
    "load_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "start = time.time()\n",
    "for _ in tqdm(load_loader, desc=\"Loading 30000 images\"): pass\n",
    "print(f\"Loaded {sampled_count} images in {(time.time()-start):.2f}s\")\n",
    "\n",
    "# Train/Val 분할\n",
    "train_img = int(0.8 * sampled_count)\n",
    "val_img = sampled_count - train_img\n",
    "train_ds, val_ds = random_split(subset_dataset, [train_img, val_img])\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# 평가용 데이터셋에서 학습에 사용된 인덱스를 제외한 나머지를 저장 - evaluate에서 사용\n",
    "unused_indices = list(set(full_indices) - set(sampled_indices))\n",
    "np.save('/content/drive/MyDrive/ProGAN/unused_indices_for_eval.npy', unused_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrXP51jUwj_N"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwdwl5VrwuRR"
   },
   "source": [
    "## Model\n",
    "\n",
    "model.ipynb 파일 내 코드를 사용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l43bUmgTw2HY"
   },
   "outputs": [],
   "source": [
    "# 채널 리스트 / steps\n",
    "channel_list = [128, 128, 128, 128, 64]\n",
    "steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AD2MYZ1cw2jw"
   },
   "outputs": [],
   "source": [
    "\"\"\" WSConv2d \"\"\"\n",
    "class WSConv2d(nn.Module):\n",
    "  # 입력 channel 수, 출력 channel 수, kernel 크기, stride(이동폭), padding(경계 처리), scale 보정 계수\n",
    "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2):\n",
    "    super().__init__()\n",
    "\n",
    "    # 기본 Conv2d layer 생성\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    # Scale 계산\n",
    "    self.scale = (gain / (in_channels * kernel_size ** 2)) ** 0.5\n",
    "\n",
    "    # Bias를 따로 저장, conv layer에서는 bias 제거\n",
    "    self.bias = self.conv.bias\n",
    "    self.conv.bias = None\n",
    "\n",
    "    # He 초기화 기준 -> weight/bias 초기화\n",
    "    # conv.weight: 정규 분포 샘플링\n",
    "    # bias: 모두 0으로 초기화\n",
    "    nn.init.normal_(self.conv.weight)\n",
    "    nn.init.zeros_(self.bias)\n",
    "\n",
    "\n",
    "\n",
    "  # 입력값 * scale -> weight scaling 효과\n",
    "  def forward(self, x):\n",
    "\n",
    "    # bias는 channel별로 reshape후 더함\n",
    "    out = self.conv(x * self.scale) + self.bias.view(1, -1, 1, 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIWnBSZiw5CE"
   },
   "outputs": [],
   "source": [
    "\"\"\" PixelNorm \"\"\"\n",
    "class PixelNorm(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # eps -> 분모에 사용\n",
    "    self.eps = 1e-8\n",
    "\n",
    "\n",
    "  # 각 픽셀마다 벡터의 크기를 1로 정규화\n",
    "  # sqrt(mean+eps)로 pixel별 norm 산출\n",
    "  # x를 norm으로 나눠 픽셀 벡터 크기 = 1로 정규화\n",
    "  def forward(self, x):\n",
    "    return x / torch.sqrt(torch.mean(x**2, dim=1, keepdim=True) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnHa7StDxAl8"
   },
   "outputs": [],
   "source": [
    "\"\"\" Up/Down Sampling \"\"\"\n",
    "class UpDownSampling(nn.Module):\n",
    "  def __init__(self, size):\n",
    "    super().__init__()\n",
    "\n",
    "    # scale_factor: 배율\n",
    "    self.size = size\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # 최근접 보간 - 해상도 전환 시 빠르고 단순한 연산 수행\n",
    "    return F.interpolate(x, scale_factor=self.size, mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g83lGaVxDQP"
   },
   "outputs": [],
   "source": [
    "\"\"\" Minibatchstd \"\"\"\n",
    "# Batch 내 통계량 추가 -> 서로 다른 샘플 간 변별력 상승\n",
    "class MinibatchStd(nn.Module):\n",
    "  def forward(self, x):\n",
    "    bs, _, h, w = x.size()\n",
    "\n",
    "    # Channel별 픽셀 표준편차 계산 -> 전체 평균 -> (bsx1xhxw) 크기로 복제\n",
    "    std = torch.std(x, dim=0).mean().repeat(bs, 1, h, w)\n",
    "\n",
    "    # 원본 feature map에 std channel을 추가 -> 미세한 차이 학습 가능\n",
    "    return torch.cat([x, std], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0B0TQxqxFty"
   },
   "outputs": [],
   "source": [
    "\"\"\" GeneratorBlock \"\"\"\n",
    "# 해상도를 2배씩 늘려 특징을 점진적으로 확장\n",
    "class GeneratorConvBlock(nn.Module):\n",
    "  def __init__(self, step, scale_size):\n",
    "    super().__init__()\n",
    "\n",
    "    # 2x upsampling layer: 크기를 scale_size배로 증가\n",
    "    self.up = UpDownSampling(scale_size)\n",
    "\n",
    "    # 2번의 WSConv + LeakyReLU + PixelNorm 반복\n",
    "    # 첫 번째 WSConv2d: 채널 수를 이전 단계 -> 현재 단계로 변환\n",
    "    self.conv1 = WSConv2d(channel_list[step-1], channel_list[step])\n",
    "\n",
    "    # 두 번째 WSConv2d: 같은 채널 수 유지하며 추가 특징 학습\n",
    "    self.conv2 = WSConv2d(channel_list[step], channel_list[step])\n",
    "\n",
    "    # LeakyReLU 적용 -> 학습 안정화\n",
    "    self.lrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    # PixelNorm: 픽셀 단위 정규화를 통한 학습 안정화\n",
    "    self.pn = PixelNorm()\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Upsampling -> 해상도 x2\n",
    "    x = self.up(x)\n",
    "\n",
    "    # 첫 번째 Conv2 -> LeakyReLU -> PixelNorm\n",
    "    x = self.lrelu(self.conv1(x))\n",
    "    x = self.pn(x)\n",
    "\n",
    "    # 두 번째 Conv2 -> LeakyReLU -> PixelNorm\n",
    "    x = self.lrelu(self.conv2(x))\n",
    "    x = self.pn(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\"\"\" Generator Structure \"\"\"\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, steps):\n",
    "    super().__init__()\n",
    "    self.steps = steps\n",
    "\n",
    "    # --- 초기 블록: 4x4 ---\n",
    "    # PixelNorm: 입력 z 정규화\n",
    "    # ConvTranspose2d: 채널 list[0] -> 채널_list[0], kernel 4x4 -> 4x4 map 생성\n",
    "    # LeakyReLU -> WSConv2d -> LeakyReLU -> PixelNorm\n",
    "    self.init = nn.Sequential(\n",
    "        PixelNorm(),\n",
    "        nn.ConvTranspose2d(channel_list[0], channel_list[0], 4, 1, 0),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        WSConv2d(channel_list[0], channel_list[0]),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        PixelNorm()\n",
    "    )\n",
    "\n",
    "    # --- Progressive Block ---\n",
    "    # init 블록 뒤 -> step=1부터 steps까지 GeneratorConvBlock 쌓기\n",
    "    # 각 block이 해상도를 2배씩 증가시키며 특징 확장\n",
    "    self.prog_blocks = nn.ModuleList([self.init] + [GeneratorConvBlock(step, 2) for step in range(1, steps+1)])\n",
    "\n",
    "    # --- toRGB layer ---\n",
    "    # 마지막 feature map을 RGB 이미지로 변환 & kernel 크기 1x1로 channel 변환만 수행\n",
    "    self.toRGB = WSConv2d(channel_list[steps], 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "\n",
    "  def forward(self, z):\n",
    "    out = z\n",
    "\n",
    "    # 초기 4x4 block\n",
    "    out = self.prog_blocks[0](out)\n",
    "\n",
    "    # 점진적 해상도 증가 블록 순차 적용(해상도 x2 -> feature map 확장)\n",
    "    for block in self.prog_blocks[1:]:\n",
    "      out = block(out)\n",
    "\n",
    "    # toRGB: 마지막 feature map을 RGB 이미지로 변환\n",
    "    return self.toRGB(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvlfnVzLxMQB"
   },
   "outputs": [],
   "source": [
    "\"\"\" DiscriminatorBlock \"\"\"\n",
    "# 해상도를 단계별로 줄이며 특징 추출\n",
    "class DiscriminatorConvBlock(nn.Module):\n",
    "    def __init__(self, step):\n",
    "      super().__init__()\n",
    "\n",
    "      # ---각 해상도별 fromRGB layer와 block을 역순으로 쌓음---\n",
    "      # 첫 번째 WSConv2d: 같은 채널 수 유지하며 nonlinear activation 전 특징 추출\n",
    "      self.conv1 = WSConv2d(channel_list[step], channel_list[step])\n",
    "\n",
    "      # 두 번째 WSConv2d: 이전 단계 채널 수로 줄이면서 세밀한 특징 학습\n",
    "      self.conv2 = WSConv2d(channel_list[step], channel_list[step-1])\n",
    "\n",
    "      # AvgPool: 해상도 절반으로 줄이는 downsampling\n",
    "      self.down = nn.AvgPool2d(2,2)\n",
    "\n",
    "      # LeakyReLU 적용 -> 학습 안정화\n",
    "      self.lrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "      # conv1 -> LeakyReLU\n",
    "      x = self.lrelu(self.conv1(x))\n",
    "\n",
    "      # conv2 -> LeakyReLU\n",
    "      x = self.lrelu(self.conv2(x))\n",
    "\n",
    "      # 해상도 절반으로 축소\n",
    "      return self.down(x)\n",
    "\n",
    "\"\"\" Discriminator Structure \"\"\"\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, steps):\n",
    "      super().__init__()\n",
    "      self.steps=steps\n",
    "\n",
    "      # 각 해상도별 fromRGB layer를 list 순서대로 저장\n",
    "      self.fromrgb_layers = nn.ModuleList()\n",
    "\n",
    "      # 단계별 Conv block을 순서대로 저장\n",
    "      self.prog_blocks = nn.ModuleList()\n",
    "\n",
    "      # 높은 해상도 -> 낮은 해상도 순으로 layer 구성\n",
    "      for s in range(steps, 0, -1):\n",
    "\n",
    "        # RGB 이미지를 channel_list[s] 만큼의 feature map으로 변환\n",
    "        self.fromrgb_layers.append(WSConv2d(3, channel_list[s], 1, 1, 0))\n",
    "\n",
    "        # 해당 해상도 단계의 ConvBlock 추가\n",
    "        self.prog_blocks.append(DiscriminatorConvBlock(s))\n",
    "\n",
    "      # 최종 해상도용 fromRGB layer\n",
    "      self.fromrgb_layers.append(WSConv2d(3,channel_list[0], 1, 1, 0))\n",
    "\n",
    "      # 최종 Discriminator block: Minibatch -> 3x3 conv -> 4x4 conv -> 1x1 conv -> Sigmoid\n",
    "      self.prog_blocks.append(nn.Sequential(\n",
    "          # 배치 표준편차 channel 추가\n",
    "          MinibatchStd(),\n",
    "          WSConv2d(channel_list[0]+1, channel_list[0], 3, 1, 1),\n",
    "          nn.LeakyReLU(0.2),\n",
    "          WSConv2d(channel_list[0], channel_list[0], 4, 1, 0),\n",
    "          nn.LeakyReLU(0.2),\n",
    "          # 최종 실수 scalar값 출력\n",
    "          WSConv2d(channel_list[0], 1, 1, 1, 0),\n",
    "          # 0~1 확률값으로 변환\n",
    "          nn.Sigmoid()\n",
    "      ))\n",
    "\n",
    "      # 추가 downsample layer 및 활성화\n",
    "      self.down = nn.AvgPool2d(2,2)\n",
    "      self.lrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "\n",
    "    # fade-in\n",
    "    def fade_in(self, alpha, down, cur):\n",
    "      # down: 이전 해상도의 특징 / cur: 현재 해상도의 특징 / alpha 비율로 보간 -> 점진적 성장 학습 안정화\n",
    "      return alpha*cur + (1-alpha)*down\n",
    "\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "      # 현재 해상도에서부터 처리 시작: fromRGB -> LeakyReLU\n",
    "      out = self.lrelu(self.fromrgb_layers[0](x))\n",
    "\n",
    "      # 현재 단계 = 0인 경우 -> 최종 판별 block으로 이동\n",
    "      if self.steps==0:\n",
    "          return self.prog_blocks[-1](out).view(out.size(0), -1)\n",
    "\n",
    "      # 이전 해상도용 특징: Downsampling -> fromRGB -> LeakyReLU\n",
    "      down = self.lrelu(self.fromrgb_layers[1](self.down(x)))\n",
    "\n",
    "      # 현재 해상도 ConvBlock 적용\n",
    "      out = self.prog_blocks[0](out)\n",
    "\n",
    "      # fade-in 보간 적용\n",
    "      out = self.fade_in(alpha, down, out)\n",
    "\n",
    "      # 남아있는 모든 ConvBlock 연쇄 적용\n",
    "      for i in range(1, self.steps+1):\n",
    "        out = self.prog_blocks[i](out)\n",
    "\n",
    "      # 최종 Discriminator 출력\n",
    "      return out.view(out.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZa6TVKXxRnw"
   },
   "source": [
    "## Train\n",
    "\n",
    "trainer.ipynb 파일 내 코드를 사용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vzj04X7xTI6"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer \"\"\"\n",
    "# Generator와 Discriminator 학습 + fade-in 기법 적용\n",
    "class Trainer():\n",
    "    def __init__(self, steps, device, train_loader, val_loader, checkpoint_path=None):\n",
    "      # Progressive 단계 수\n",
    "      self.steps = steps\n",
    "      self.device = device\n",
    "      self.train_loader = train_loader\n",
    "      self.val_loader = val_loader\n",
    "\n",
    "      # Generator & Discriminator 모델 -> device\n",
    "      self.generator = Generator(steps).to(device)\n",
    "      self.discriminator = Discriminator(steps).to(device)\n",
    "\n",
    "      # 이진 분류용 loss function -> 진짜 vs 가짜\n",
    "      self.criterion = nn.BCELoss()\n",
    "\n",
    "      # Optimizer: Adam\n",
    "      self.g_opt = Adam(self.generator.parameters(), lr=0.003, betas=(0.0,0.99))\n",
    "      self.d_opt = Adam(self.discriminator.parameters(), lr=0.001, betas=(0.0,0.99))\n",
    "\n",
    "      # ---fade-in 제어---\n",
    "      self.alpha = 0\n",
    "      # 한 epoch 동안 alpha가 0~1이 되도록 조정\n",
    "      self.alpha_gap = 1 / (len(train_loader) * 5) # 총 5 epoch동안 전환\n",
    "\n",
    "      self.final_sample_dir = \"/content/drive/MyDrive/ProGAN/Final_images\" # 최종 생성 이미지 저장 위치 - 변경 가능\n",
    "      os.makedirs(self.final_sample_dir, exist_ok=True)\n",
    "\n",
    "      self.epoch_image_dir = \"/content/drive/MyDrive/ProGAN/epoch_images\" # 각 epoch 별 이미지 저장 위치 - 변경 가능\n",
    "      os.makedirs(self.epoch_image_dir, exist_ok=True)\n",
    "\n",
    "      self.checkpoint_dir = \"/content/drive/MyDrive/ProGAN/checkpoints\" # checkpoint 저장 위치 - 변경 가능\n",
    "      os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "      # ---Sampling용 고정 noise---\n",
    "      # 매 epoch마다 같은 z 입력 -> 생성 결과 변화 비교\n",
    "      self.test_z = torch.randn(1, 128, 1, 1, device=self.device)\n",
    "      self.test_z_last = torch.randn(50, 128, 1, 1, device=self.device)\n",
    "\n",
    "      self.start_epoch = 0\n",
    "      self.history = {'g_train': [], 'd_train': [], 'g_val': [], 'd_val': []}\n",
    "\n",
    "      if checkpoint_path is not None:\n",
    "        self._load_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Save checkpoint\n",
    "    def _save_checkpoint(self, epoch):\n",
    "      path = os.path.join(self.checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\") # Google Drive 내에 저장하는 것을 추천드립니다.(런타임 끊기는 것을 대비)\n",
    "      torch.save({\n",
    "          'epoch': epoch,\n",
    "          'generator': self.generator.state_dict(),\n",
    "          'discriminator': self.discriminator.state_dict(),\n",
    "          'g_opt': self.g_opt.state_dict(),\n",
    "          'd_opt': self.d_opt.state_dict(),\n",
    "          'alpha': self.alpha,\n",
    "          'history': self.history\n",
    "      }, path)\n",
    "      print(f\"Checkpoint saved: {path}\")\n",
    "\n",
    "\n",
    "    # Load checkpoint\n",
    "    def _load_checkpoint(self, path):\n",
    "      checkpoint = torch.load(path)\n",
    "      self.generator.load_state_dict(checkpoint['generator'])\n",
    "      self.discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "      self.g_opt.load_state_dict(checkpoint['g_opt'])\n",
    "      self.d_opt.load_state_dict(checkpoint['d_opt'])\n",
    "      self.alpha = checkpoint['alpha']\n",
    "      self.start_epoch = checkpoint['epoch'] + 1\n",
    "      self.history = checkpoint['history']\n",
    "      print(f\"Resuming training from epoch {self.start_epoch}\")\n",
    "\n",
    "\n",
    "    # 매 epoch 후 고정 노이즈로 이미지 생성 및 저장\n",
    "    def save_epoch_image(self, epoch):\n",
    "      # BatchNorm, Dropout 비활성화\n",
    "      self.generator.eval()\n",
    "      with torch.no_grad():\n",
    "        fake = self.generator(self.test_z)\n",
    "        save_image(fake[0], f\"{self.epoch_image_dir}/epoch_{epoch:03d}.png\", normalize=True, value_range=(-1, 1))\n",
    "\n",
    "    # 마지막 epoch 최종 이미지 생성 및 저장\n",
    "    def save_last_epoch_image(self, epoch):\n",
    "      self.generator.eval()\n",
    "      with torch.no_grad():\n",
    "        fake = self.generator(self.test_z_last)\n",
    "        for i in range(fake.size(0)):\n",
    "          save_image(fake[i], f\"{self.final_sample_dir}/epoch_{epoch:03d}_sample_{i:02d}.png\", normalize=True, value_range=(-1, 1))\n",
    "\n",
    "\n",
    "    # 한 epoch동안 Generator와 Discriminator 학습\n",
    "    def train_epoch(self):\n",
    "      self.generator.train()\n",
    "      self.discriminator.train()\n",
    "      g_loss_avg = 0\n",
    "      d_loss_avg = 0\n",
    "\n",
    "      for real in self.train_loader:\n",
    "        real = real.to(self.device)\n",
    "\n",
    "        # batch size\n",
    "        bs = real.size(0)\n",
    "        real_lbl = torch.full((bs, 1), 0.9, device=self.device)\n",
    "        fake_lbl = torch.full((bs, 1), 0.1, device=self.device)\n",
    "\n",
    "        # ---Discriminator Train---\n",
    "        # 가짜 이미지 생성\n",
    "        z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "        fake = self.generator(z)\n",
    "\n",
    "        # 진짜/가짜 판별\n",
    "        d_fake = self.discriminator(fake.detach(), self.alpha)\n",
    "        d_real = self.discriminator(real, self.alpha)\n",
    "\n",
    "        # loss 계산 - 진짜 = 1, 가짜 = 0\n",
    "        d_loss = self.criterion(d_fake, fake_lbl) + self.criterion(d_real, real_lbl)\n",
    "\n",
    "        # 역전파 & parameter 업데이트\n",
    "        self.d_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.d_opt.step()\n",
    "\n",
    "        # 두 loss의 평균값\n",
    "        d_loss_avg += d_loss.item()/2\n",
    "\n",
    "        # ---Generator Train---\n",
    "        # 새로운 노이즈로 가짜 이미지 생성\n",
    "        for _ in range(2):\n",
    "          z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "          fake = self.generator(z)\n",
    "\n",
    "          # Discriminator가 가짜를 진짜로 판단하도록 유도\n",
    "          g_loss = self.criterion(self.discriminator(fake, self.alpha), real_lbl)\n",
    "\n",
    "          # 역전파 & parameter 업데이트\n",
    "          self.g_opt.zero_grad()\n",
    "          g_loss.backward()\n",
    "          self.g_opt.step()\n",
    "          g_loss_avg += g_loss.item()\n",
    "\n",
    "        # fade-in 비율 업데이트 - block 간 부드러운 전환\n",
    "        self.alpha = min(1, self.alpha + self.alpha_gap)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "      # epcoh 별 평균 loss 반환\n",
    "      return g_loss_avg/len(self.train_loader), d_loss_avg/len(self.train_loader)\n",
    "\n",
    "\n",
    "    def valid_epoch(self):\n",
    "      # 한 epoch 동안 Generator/Discriminator의 validation loss 계산\n",
    "      self.generator.eval()\n",
    "      self.discriminator.eval()\n",
    "      g_loss_avg = 0\n",
    "      d_loss_avg = 0\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for real in self.val_loader:\n",
    "          real = real.to(self.device)\n",
    "          bs = real.size(0)\n",
    "          real_lbl = torch.full((bs, 1), 0.9, device=self.device)\n",
    "          fake_lbl = torch.full((bs, 1), 0.1, device=self.device)\n",
    "\n",
    "          # Discriminator 검증\n",
    "          z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "          fake = self.generator(z)\n",
    "          d_fake = self.discriminator(fake, self.alpha)\n",
    "          d_real = self.discriminator(real, self.alpha)\n",
    "          d_loss_avg += (self.criterion(d_fake, fake_lbl) + self.criterion(d_real, real_lbl)).item() / 2\n",
    "\n",
    "          # Generator 검증\n",
    "          z = torch.randn(bs, 128, 1, 1, device=self.device)\n",
    "          fake = self.generator(z)\n",
    "          g_loss_avg += self.criterion(self.discriminator(fake, self.alpha), real_lbl).item()\n",
    "\n",
    "      return g_loss_avg/len(self.val_loader), d_loss_avg/len(self.val_loader)\n",
    "\n",
    "\n",
    "    # 지정된 epoch 수만큼 학습 및 검증을 수행하고 epoch마다 이미지 저장\n",
    "    def run(self, epochs):\n",
    "      for epoch in range(self.start_epoch, epochs):\n",
    "        # 학습 & validation loss 계산\n",
    "        g_t, d_t = self.train_epoch()\n",
    "        g_v, d_v = self.valid_epoch()\n",
    "        self.history['g_train'].append(g_t)\n",
    "        self.history['d_train'].append(d_t)\n",
    "        self.history['g_val'].append(g_v)\n",
    "        self.history['d_val'].append(d_v)\n",
    "\n",
    "        # loss log 출력\n",
    "        print(f\"Epoch {epoch}: G_loss {g_t:.4f}/{g_v:.4f}, D_loss {d_t:.4f}/{d_v:.4f}\")\n",
    "\n",
    "        # epoch별 생성 이미지 저장\n",
    "        self.save_epoch_image(epoch)\n",
    "        self._save_checkpoint(epoch)\n",
    "\n",
    "        # 마지막 epoch -> 50개 개별 이미지도 저장\n",
    "        if epoch == epochs - 1:\n",
    "          self.save_last_epoch_image(epoch)\n",
    "          self._save_checkpoint(epoch)\n",
    "\n",
    "      return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CEX-L3bxfps"
   },
   "outputs": [],
   "source": [
    "\"\"\" Train \"\"\"\n",
    "\n",
    "# 설정\n",
    "epochs = 40\n",
    "checkpoint_path = None  # 이어 학습하고 싶은 checkpoint 파일 경로 (없으면 None)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 학습 실행\n",
    "trainer = Trainer(\n",
    "    steps=steps,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    checkpoint_path=checkpoint_path # checkpoint 경로\n",
    ")\n",
    "\n",
    "history = trainer.run(epochs=epochs)\n",
    "\n",
    "# 최적 epoch 출력\n",
    "best_epoch = int(np.argmin(history['g_val']))\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['g_train'], label='G_train')\n",
    "plt.plot(history['g_val'], label='G_val')\n",
    "plt.title('Generator Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['d_train'], label='D_train')\n",
    "plt.plot(history['d_val'], label='D_val')\n",
    "plt.title('Discriminator Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 최종 모델 저장\n",
    "torch.save(trainer.generator.state_dict(), 'Generator_final.pt')\n",
    "torch.save(trainer.discriminator.state_dict(), 'Discriminator_final.pt')\n",
    "print(\"모델 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "X5Sxlc50vuIe",
    "fk7mjX7LvzIQ",
    "JQGpwR-Jv4hU",
    "dwdwl5VrwuRR",
    "bZa6TVKXxRnw"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
